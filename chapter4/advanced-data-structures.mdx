---
title: Advanced Data Structures
description: Learn how to combine Python's built-in data structures to solve complex problems efficiently
---

# Advanced Data Structures

Now that we've covered Python's core built-in data structures—lists, tuples, dictionaries, and sets—let's explore how to combine them to create more advanced data structures and solve complex problems efficiently. By composing these fundamental building blocks, you can create powerful custom data structures tailored to specific requirements.

## Combining Data Structures

### Nested Structures

Python's data structures can be nested within each other to represent complex data:

```python
# List of dictionaries (common for representing collections of objects)
students = [
    {"name": "Alice", "age": 20, "grades": [85, 90, 88]},
    {"name": "Bob", "age": 22, "grades": [92, 86, 94]},
    {"name": "Charlie", "age": 21, "grades": [78, 81, 85]}
]

# Dictionary of lists (grouping related items)
school_classes = {
    "math": ["Alice", "Bob", "Eve"],
    "science": ["Charlie", "Dave", "Eve"],
    "history": ["Alice", "Charlie", "Frank"]
}

# Dictionary of dictionaries (complex mapping relationships)
user_profiles = {
    "user123": {
        "name": "Alice Smith",
        "email": "alice@example.com",
        "preferences": {"theme": "dark", "notifications": True}
    },
    "user456": {
        "name": "Bob Johnson",
        "email": "bob@example.com",
        "preferences": {"theme": "light", "notifications": False}
    }
}
```

### Working with Nested Structures

When working with nested structures, you'll often need to navigate through multiple levels:

```python
# Get the average grade for each student
for student in students:
    grades = student["grades"]
    average = sum(grades) / len(grades)
    print(f"{student['name']}: {average:.2f}")

# Find students in multiple classes
class_enrollments = {}
for subject, enrolled_students in school_classes.items():
    for student in enrolled_students:
        if student not in class_enrollments:
            class_enrollments[student] = []
        class_enrollments[student].append(subject)

multiple_classes = {student: subjects for student, subjects in class_enrollments.items() 
                   if len(subjects) > 1}
print(f"Students in multiple classes: {multiple_classes}")
```

## Advanced Techniques

### Custom Collections with `collections` Module

The `collections` module provides specialized container data types that extend the functionality of Python's built-in containers:

```python
from collections import defaultdict, Counter, deque, namedtuple, ChainMap

# defaultdict: A dictionary that provides default values for missing keys
word_categories = defaultdict(list)
words = ["apple", "banana", "avocado", "blueberry", "cherry"]
for word in words:
    word_categories[word[0]].append(word)
print(word_categories)  # {'a': ['apple', 'avocado'], 'b': ['banana', 'blueberry'], 'c': ['cherry']}

# Counter: A dictionary for counting hashable objects
text = "how much wood would a woodchuck chuck if a woodchuck could chuck wood"
word_counts = Counter(text.split())
print(word_counts)  # Counter({'wood': 2, 'woodchuck': 2, 'chuck': 2, 'a': 2, 'how': 1, 'much': 1, 'would': 1, 'if': 1, 'could': 1})
print(word_counts.most_common(2))  # [('wood', 2), ('woodchuck', 2)]

# deque: A double-ended queue with fast append/pop on either end
tasks = deque(["task1", "task2", "task3"])
tasks.appendleft("urgent_task")    # Add to the left
tasks.append("new_task")           # Add to the right
first_task = tasks.popleft()       # Remove from the left
print(tasks)  # deque(['task1', 'task2', 'task3', 'new_task'])

# namedtuple: A tuple with named fields
Point = namedtuple('Point', ['x', 'y', 'z'])
p = Point(1, 2, 3)
print(p.x, p.y, p.z)  # 1 2 3
print(p[0], p[1], p[2])  # 1 2 3

# ChainMap: Search through multiple mappings as a single unit
defaults = {'theme': 'dark', 'language': 'en'}
user_settings = {'theme': 'light'}
settings = ChainMap(user_settings, defaults)
print(settings['theme'])     # 'light' from user_settings
print(settings['language'])  # 'en' from defaults
```

### Efficient Data Organization

#### Lookup Tables for O(1) Access

When you need fast lookups, dictionaries or sets provide O(1) average time complexity:

```python
# Creating a lookup table from a list of items
users = [
    {"id": 1, "username": "alice", "email": "alice@example.com"},
    {"id": 2, "username": "bob", "email": "bob@example.com"},
    {"id": 3, "username": "charlie", "email": "charlie@example.com"}
]

# Fast lookup by ID
users_by_id = {user["id"]: user for user in users}
print(users_by_id[2])  # Access user with ID 2

# Fast lookup by username
users_by_username = {user["username"]: user for user in users}
print(users_by_username["alice"])  # Access user with username "alice"

# Multiple lookup tables for the same data
users_by_email = {user["email"]: user for user in users}
```

#### Bidirectional Mappings

Sometimes you need to look up values by keys and keys by values:

```python
class BiDict:
    """A bidirectional dictionary for one-to-one mappings."""
    
    def __init__(self, mapping=None):
        self.forward = {}
        self.backward = {}
        if mapping:
            for key, value in mapping.items():
                self[key] = value
    
    def __setitem__(self, key, value):
        # Remove old mappings if they exist
        if key in self.forward:
            del self.backward[self.forward[key]]
        if value in self.backward:
            del self.forward[self.backward[value]]
        
        # Add new mappings
        self.forward[key] = value
        self.backward[value] = key
    
    def __getitem__(self, key):
        return self.forward[key]
    
    def get_key(self, value):
        return self.backward[value]
    
    def __delitem__(self, key):
        value = self.forward[key]
        del self.backward[value]
        del self.forward[key]
    
    def __iter__(self):
        return iter(self.forward)


# Example usage
country_codes = BiDict({"US": "United States", "CA": "Canada", "MX": "Mexico"})
print(country_codes["US"])              # "United States"
print(country_codes.get_key("Canada"))  # "CA"

# Update a mapping
country_codes["UK"] = "United Kingdom"
print(country_codes.get_key("United Kingdom"))  # "UK"
```

#### Index Structures for Fast Search

Creating indices for different search criteria can make operations more efficient:

```python
class Indexer:
    """A class that indexes objects by multiple fields for fast lookup."""
    
    def __init__(self):
        self.objects = []
        self.indices = {}
    
    def add_object(self, obj):
        """Add an object to the indexer."""
        self.objects.append(obj)
        obj_index = len(self.objects) - 1
        
        # Index every attribute of the object
        for key, value in obj.items():
            if key not in self.indices:
                self.indices[key] = {}
            
            if value not in self.indices[key]:
                self.indices[key][value] = []
            
            self.indices[key][value].append(obj_index)
    
    def find(self, **criteria):
        """Find objects matching the given criteria."""
        if not criteria:
            return list(self.objects)  # Return all if no criteria
        
        # Start with the most selective criterion
        candidate_indices = None
        
        for key, value in criteria.items():
            if key not in self.indices or value not in self.indices[key]:
                return []  # No match for this criterion
            
            # Get indices of objects matching this criterion
            matching_indices = set(self.indices[key][value])
            
            if candidate_indices is None:
                candidate_indices = matching_indices
            else:
                # Intersect with previous matches
                candidate_indices &= matching_indices
            
            if not candidate_indices:
                return []  # No objects match all criteria
        
        # Return the matching objects
        return [self.objects[i] for i in candidate_indices]


# Example usage
indexer = Indexer()

# Add objects to the indexer
users = [
    {"id": 1, "name": "Alice", "department": "IT", "role": "Developer"},
    {"id": 2, "name": "Bob", "department": "HR", "role": "Manager"},
    {"id": 3, "name": "Charlie", "department": "IT", "role": "Manager"},
    {"id": 4, "name": "Diana", "department": "Finance", "role": "Analyst"},
    {"id": 5, "name": "Eve", "department": "IT", "role": "Analyst"}
]

for user in users:
    indexer.add_object(user)

# Find IT Managers
it_managers = indexer.find(department="IT", role="Manager")
print(it_managers)  # [{"id": 3, "name": "Charlie", "department": "IT", "role": "Manager"}]

# Find all Analysts
all_analysts = indexer.find(role="Analyst")
print(all_analysts)  # [{"id": 4, ...}, {"id": 5, ...}]
```

## Specialized Data Structures

### Implementing a Cache with TTL (Time to Live)

A cache that automatically expires entries after a specified time:

```python
import time
from collections import OrderedDict

class TTLCache:
    """A cache with a time-to-live (TTL) for entries."""
    
    def __init__(self, max_size=100, ttl=60):
        self.cache = OrderedDict()
        self.max_size = max_size
        self.ttl = ttl  # Time to live in seconds
    
    def __setitem__(self, key, value):
        """Add an item to the cache with current timestamp."""
        self._evict_expired()
        
        # If at capacity, remove the oldest item
        if len(self.cache) >= self.max_size:
            self.cache.popitem(last=False)
        
        self.cache[key] = (value, time.time())
        self.cache.move_to_end(key)  # Move to end (newest)
    
    def __getitem__(self, key):
        """Get an item from the cache if it exists and is not expired."""
        self._evict_expired()
        
        if key in self.cache:
            value, timestamp = self.cache[key]
            
            # Check if expired
            if time.time() - timestamp > self.ttl:
                del self.cache[key]
                raise KeyError(key)
            
            # Move to end (mark as recently used)
            self.cache.move_to_end(key)
            return value
        
        raise KeyError(key)
    
    def _evict_expired(self):
        """Remove all expired entries from the cache."""
        current_time = time.time()
        expired_keys = [k for k, (_, t) in self.cache.items() 
                       if current_time - t > self.ttl]
        
        for key in expired_keys:
            del self.cache[key]
    
    def __contains__(self, key):
        """Check if a key exists in the cache and is not expired."""
        try:
            _ = self[key]
            return True
        except KeyError:
            return False


# Example usage
cache = TTLCache(max_size=2, ttl=5)  # Small cache with 5-second TTL
cache["a"] = 1
cache["b"] = 2
print(cache["a"])  # 1

# This would remove "a" from the cache due to max_size
cache["c"] = 3
try:
    print(cache["a"])  # Will raise KeyError
except KeyError:
    print("'a' is no longer in the cache")

# Wait for TTL to expire
import time
time.sleep(6)
try:
    print(cache["b"])  # Will raise KeyError
except KeyError:
    print("'b' has expired")
```

### Priority Queue Implementation

A priority queue that allows efficient retrieval of the highest-priority item:

```python
import heapq

class PriorityQueue:
    """A queue where items are dequeued based on priority."""
    
    def __init__(self):
        self._queue = []
        self._index = 0  # Used for stable sorting
    
    def push(self, item, priority):
        """Add an item to the queue with given priority."""
        # We use negative priority so that higher values are higher priority
        heapq.heappush(self._queue, (-priority, self._index, item))
        self._index += 1
    
    def pop(self):
        """Remove and return the highest priority item."""
        if not self._queue:
            raise IndexError("pop from an empty priority queue")
        return heapq.heappop(self._queue)[2]
    
    def peek(self):
        """Return the highest priority item without removing it."""
        if not self._queue:
            raise IndexError("peek from an empty priority queue")
        return self._queue[0][2]
    
    def __len__(self):
        return len(self._queue)
    
    def __bool__(self):
        return bool(self._queue)


# Example usage
task_queue = PriorityQueue()
task_queue.push("Low priority task", 1)
task_queue.push("High priority task", 3)
task_queue.push("Medium priority task", 2)

print(task_queue.pop())  # "High priority task"
print(task_queue.pop())  # "Medium priority task"
print(task_queue.pop())  # "Low priority task"
```

### Trie for Prefix Searches

A trie (prefix tree) is efficient for storing and searching strings with common prefixes:

```python
class TrieNode:
    """A node in the trie structure."""
    
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False


class Trie:
    """A trie data structure for efficient string prefix operations."""
    
    def __init__(self):
        self.root = TrieNode()
    
    def insert(self, word):
        """Insert a word into the trie."""
        node = self.root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end_of_word = True
    
    def search(self, word):
        """Search for a word in the trie."""
        node = self.root
        for char in word:
            if char not in node.children:
                return False
            node = node.children[char]
        return node.is_end_of_word
    
    def starts_with(self, prefix):
        """Check if any words in the trie start with the given prefix."""
        node = self.root
        for char in prefix:
            if char not in node.children:
                return False
            node = node.children[char]
        return True
    
    def get_words_with_prefix(self, prefix):
        """Get all words in the trie with the given prefix."""
        result = []
        node = self.root
        
        # Navigate to the prefix node
        for char in prefix:
            if char not in node.children:
                return result
            node = node.children[char]
        
        # Collect all words from this point
        self._collect_words(node, prefix, result)
        return result
    
    def _collect_words(self, node, prefix, result):
        """Recursively collect all words starting from the given node."""
        if node.is_end_of_word:
            result.append(prefix)
        
        for char, child in node.children.items():
            self._collect_words(child, prefix + char, result)


# Example usage
trie = Trie()
words = ["apple", "app", "apricot", "banana", "bat", "ball"]
for word in words:
    trie.insert(word)

print(trie.search("apple"))      # True
print(trie.search("application"))  # False
print(trie.starts_with("app"))   # True
print(trie.starts_with("ban"))   # True
print(trie.get_words_with_prefix("ap"))  # ["app", "apple", "apricot"]
print(trie.get_words_with_prefix("ba"))  # ["banana", "bat", "ball"]
```

## Case Study: Building a Document Index System

Let's put all these concepts together to build a simple document indexing and search system:

```python
import re
from collections import defaultdict

class DocumentIndex:
    """A system for indexing and searching a collection of documents."""
    
    def __init__(self):
        self.documents = {}  # Map document ID to document text
        self.term_index = defaultdict(set)  # Map term to document IDs
        self.doc_count = 0  # Counter for document IDs
    
    def add_document(self, text, doc_id=None):
        """Add a document to the index."""
        if doc_id is None:
            doc_id = self.doc_count
            self.doc_count += 1
        
        # Store the document
        self.documents[doc_id] = text
        
        # Index the document terms
        terms = self._tokenize(text)
        for term in terms:
            self.term_index[term].add(doc_id)
        
        return doc_id
    
    def search(self, query):
        """
        Search the index for documents matching the query.
        Supports simple boolean queries with AND (space) and OR (|).
        """
        # Split by OR operator
        or_terms = query.split('|')
        results = set()
        
        for or_term in or_terms:
            # Split by AND (implicit space)
            and_terms = or_term.strip().split()
            
            if not and_terms:
                continue
            
            # Start with all documents matching the first term
            term_results = self.term_index.get(and_terms[0].lower(), set())
            
            # Require all other terms to match (AND operation)
            for term in and_terms[1:]:
                term_results &= self.term_index.get(term.lower(), set())
            
            # Add to overall results (OR operation)
            results |= term_results
        
        # Return the matching documents
        return [(doc_id, self.documents[doc_id]) for doc_id in results]
    
    def _tokenize(self, text):
        """Convert text to lowercase tokens, removing punctuation."""
        # Simple tokenization - convert to lowercase and split on non-alphanumeric
        return set(re.sub(r'[^\w\s]', '', text.lower()).split())


# Example usage
index = DocumentIndex()

# Add some documents
doc1 = """Python is a high-level, general-purpose programming language. Its design philosophy 
          emphasizes code readability with the use of significant indentation."""
doc2 = """Python is dynamically-typed and garbage-collected. It supports multiple programming paradigms, 
          including structured, object-oriented, and functional programming."""
doc3 = """Python is one of the most popular programming languages and is not related to snakes. 
          It was created by Guido van Rossum."""

index.add_document(doc1)
index.add_document(doc2)
index.add_document(doc3)

# Search for documents
print("Search for 'python':")
for doc_id, doc in index.search("python"):
    print(f"Document {doc_id}: {doc[:50]}...")

print("\nSearch for 'programming language':")
for doc_id, doc in index.search("programming language"):
    print(f"Document {doc_id}: {doc[:50]}...")

print("\nSearch for 'python | snakes':")
for doc_id, doc in index.search("python | snakes"):
    print(f"Document {doc_id}: {doc[:50]}...")
```

## Best Practices for Complex Data Structures

When working with complex nested data structures, follow these best practices:

1. **Document your structures**: Always document the expected structure and purpose of complex data structures.

2. **Use consistent patterns**: Establish patterns for how you structure your data and follow them consistently.

3. **Consider access patterns**: Design your data structures based on how you'll most frequently access the data.

4. **Balance depth and breadth**: Excessively deep nesting can be hard to navigate; consider flattening when appropriate.

5. **Use named collections**: For complex structures, consider using classes or named tuples to make the code more readable.

6. **Test with sample data**: Create small examples to verify your structure works as expected before scaling up.

7. **Provide helper functions**: Implement utility functions to handle common operations on your data structures.

## Practice Exercises

1. Implement a `MultiMap` data structure that maps keys to multiple values, with methods to add, get, and remove values associated with a key.

2. Create a `LRUCache` (Least Recently Used Cache) that maintains a specified maximum number of items, discarding the least recently used item when full.

3. Implement a `Graph` class using adjacency lists (dictionaries of sets) to represent an undirected graph, with methods to add vertices, add edges, and perform a breadth-first search.

4. Create a `SparseMatrix` implementation that efficiently stores and operates on matrices with mostly zero values.

5. Design and implement a `FileSystem` class that simulates a hierarchical file system with directories and files, using nested dictionaries.

## Summary

Advanced data structures combine Python's built-in types to solve complex problems efficiently. By understanding the characteristics of lists, tuples, dictionaries, and sets, you can create powerful custom structures tailored to your specific needs.

Key points to remember:

- Nested data structures allow you to represent complex relationships
- The `collections` module provides specialized containers for common patterns
- Custom classes can encapsulate complex data structures with domain-specific operations
- The right data structure can dramatically improve performance for specific operations
- Consider access patterns when designing your data structures

In the next chapter, we'll explore Advanced Python Concepts, including decorators, generators, context managers, and functional programming techniques that will further enhance your Python programming skills. 